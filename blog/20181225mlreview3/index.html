<!DOCTYPE html>
<html lang="zh" >

<head>
    <meta charset="UTF-8"><meta http-equiv="Content-Security-Policy"
content="default-src 'self';font-src &#x27;self&#x27; data: 'self';img-src &#x27;self&#x27; https:&#x2F;&#x2F;* data:;media-src &#x27;self&#x27;;style-src &#x27;self&#x27; 'unsafe-inline';frame-src player.vimeo.com https:&#x2F;&#x2F;www.youtube-nocookie.com;connect-src 'self';script-src 'self' 'self'">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="base" content="https://blog.littleji.com">

    
    <title>littleji's blog • ML梳理之线性回归(DecisionTree)</title>

    
    
    

    
    

    
    
    
        
            <link rel="stylesheet" href="https://blog.littleji.com/custom_subset.css?h=0b9535a28bc3d5bf2321">
        
    

    
        <link rel="stylesheet" href="https://blog.littleji.com/main.css?h=e38cfa6902d00356cd66" />

    <meta name="color-scheme" content="light dark" />
        <meta name="description" content="" />
        <meta property="og:description" content="" />

    

    <meta property="og:title" content="ML梳理之线性回归(DecisionTree)" />
    <meta property="og:type" content="article" />

    
<meta property="og:locale" content="en_GB" />

    <meta property="og:url" content="https:&#x2F;&#x2F;blog.littleji.com&#x2F;blog&#x2F;20181225mlreview3&#x2F;" /><meta property="og:site_name" content="littleji&#x27;s blog">
        <noscript><link rel="stylesheet" href="https://blog.littleji.com/no_js.css"/></noscript>
        <script type="text/javascript" src="https://blog.littleji.com/js/initializeTheme.min.js"></script>
        <script defer src="https://blog.littleji.com/js/themeSwitcher.min.js"></script>
        <script defer src="https://blog.littleji.com/js/searchElasticlunr.min.js?h=3626c0ef99daa745b31e"></script>

        <script defer src="https://blog.littleji.com/js/lunr/lunrStemmerSupport.min.js"></script>
            <script defer src="https://blog.littleji.com/js/lunr/lunr.zh.min.js"></script></head>


<body>
    <header>
    <nav class="navbar">
        <div class="nav-title">
            <a class="home-title" href="https://blog.littleji.com">littleji&#x27;s blog</a>
        </div>
            <div class="nav-navs">
                <ul>
                        
                            <li>
                                <a class="nav-links no-hover-padding" href="https://blog.littleji.com/blog/">home
                                </a>
                            </li>
                        
                            <li>
                                <a class="nav-links no-hover-padding" href="https://blog.littleji.com/archive/">archive
                                </a>
                            </li>
                        
                            <li>
                                <a class="nav-links no-hover-padding" href="https://blog.littleji.com/tags/">tags
                                </a>
                            </li>
                        
                            <li>
                                <a class="nav-links no-hover-padding" href="https:&#x2F;&#x2F;github.com&#x2F;littleji">github
                                </a>
                            </li>
                        
                            <li>
                                <a class="nav-links no-hover-padding" href="https://blog.littleji.com/projects/">projects
                                </a>
                            </li>
                        <li class="menu-icons-container">
                        <ul class="menu-icons-group">
                            <li class="js menu-icon">
                                <div role="button" tabindex="0" id="search-button" class="search-icon interactive-icon" title="Press $SHORTCUT to open search" aria-label="Press $SHORTCUT to open search">
                                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 -960 960 960">
                                        <path d="M784-120 532-372q-30 24-69 38t-83 14q-109 0-184.5-75.5T120-580q0-109 75.5-184.5T380-840q109 0 184.5 75.5T640-580q0 44-14 83t-38 69l252 252-56 56ZM380-400q75 0 127.5-52.5T560-580q0-75-52.5-127.5T380-760q-75 0-127.5 52.5T200-580q0 75 52.5 127.5T380-400Z"/>
                                    </svg>
                                </div>
                            </li>

                            
                            

                            <li class="theme-switcher-wrapper js"><div
        title="Toggle dark&#x2F;light mode"
        class="theme-switcher"
        tabindex="0"
        role="button"
        aria-label="Toggle dark mode"
        aria-pressed="false">
    </div><div
        title="Reset mode to default"
        class="theme-resetter arrow"
        tabindex="0"
        role="button"
        aria-hidden="true"
        aria-label="Reset mode to default">
    </div>

</li>
</ul>
                    </li>
                </ul>
            </div>
        
    </nav>
</header>

    <div class="content">

        
        




<main>
    <article>
        <h1 class="article-title">
            ML梳理之线性回归(DecisionTree)
        </h1>

        <ul class="meta">
                <li>25th Dec 2018</li><li title="1888 words"><span class='separator' aria-hidden='true'>•</span>10 min read</li><li class="tag"><span class='separator' aria-hidden='true'>•</span>Tags:&nbsp;</li><li class="tag"><a href="https://blog.littleji.com/tags/ji-qi-xue-xi-machinelearning/">机器学习(MachineLearning)</a></li></ul><ul class="meta last-updated"><li>Updated on 8th Feb 2025</li>
        </ul>
            

<div class="toc-container">
    
        <h3>Table of Contents</h3>
    

    <ul>
        
            
            
                <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#xin-xi-lun-ji-chu">信息论基础</a>
                    
                        <ul>
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#shang">熵</a>
                                        
                                    </li>
                                
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#lian-he-shang">联合熵</a>
                                        
                                    </li>
                                
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#tiao-jian-shang">条件熵</a>
                                        
                                    </li>
                                
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#xin-xi-zeng-yi">信息增益</a>
                                        
                                    </li>
                                
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#ji-ni-bu-chun-du">基尼不纯度</a>
                                        
                                    </li>
                                
                            
                        </ul>
                    
                </li>
            
        
            
            
                <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#jue-ce-shu-de-bu-tong-fen-lei-suan-fa">决策树的不同分类算法</a>
                    
                        <ul>
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#id3suan-fa">ID3算法</a>
                                        
                                    </li>
                                
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#c4-5">C4.5</a>
                                        
                                    </li>
                                
                            
                        </ul>
                    
                </li>
            
        
            
            
                <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#hui-gui-shu-yuan-li">回归树原理</a>
                    
                        <ul>
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#cartfen-lei-shu">CART分类树</a>
                                        
                                            <ul>
                                                
                                                    
                                                        <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#cartde-sheng-cheng">CART的生成</a>
                                                            
                                                        </li>
                                                    
                                                
                                                    
                                                        <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#cartde-jian-zhi">CART的剪枝</a>
                                                            
                                                        </li>
                                                    
                                                
                                            </ul>
                                        
                                    </li>
                                
                            
                        </ul>
                    
                </li>
            
        
            
            
                <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#jue-ce-shu-fang-zhi-guo-ni-he-shou-duan">决策树防止过拟合手段</a>
                    
                </li>
            
        
            
            
                <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#mo-xing-ping-gu">模型评估</a>
                    
                </li>
            
        
            
            
                <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#pythonke-shi-hua-jue-ce-shu-yu-dui-ying-de-han-shu-shi-xian">python可视化决策树与对应的函数实现</a>
                    
                </li>
            
        
            
            
                <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#can-kao">参考</a>
                    
                </li>
            
        
    </ul>
</div>


        

        <section class="body"><h1 id="xin-xi-lun-ji-chu"><a class="header-anchor no-hover-padding" href="#xin-xi-lun-ji-chu" aria-label="Anchor link for: xin-xi-lun-ji-chu"><span class="link-icon" aria-hidden="true"></span></a>
信息论基础</h1>
<p>信息论的基础由香农博士于1948年奠定.下面说明关于信息论的一些基本概念.</p>
<h2 id="shang"><a class="header-anchor no-hover-padding" href="#shang" aria-label="Anchor link for: shang"><span class="link-icon" aria-hidden="true"></span></a>
熵</h2>
<p>上表示一个随机变量不确定的数量.如果一个随机变量的熵越大,那么其不确定也就越大.
如果$X$为离散型变量,取值为$\mathbb R$,其概率分布为$p(x)=P(X=x),x\in \mathbb R$,那么X的熵$H(X)$定义为:
$$
H(X)=-\sum_{x \in R}p(x)log_2p(x)
$$</p>
<h2 id="lian-he-shang"><a class="header-anchor no-hover-padding" href="#lian-he-shang" aria-label="Anchor link for: lian-he-shang"><span class="link-icon" aria-hidden="true"></span></a>
联合熵</h2>
<p>联合熵其实就是描述一对随机变量平均所需要的信息量.
如果$X,Y$是一对离散型随机变量 $X,Y ~ p(x,y),X,Y$的联合熵为$H(X,Y)$为:
$$
H(X,Y)=-\sum_{x \in X}\sum_{y \in Y}p(x,y)logp(x,y)
$$</p>
<h2 id="tiao-jian-shang"><a class="header-anchor no-hover-padding" href="#tiao-jian-shang" aria-label="Anchor link for: tiao-jian-shang"><span class="link-icon" aria-hidden="true"></span></a>
条件熵</h2>
<p>条件熵$H(Y|X)$的意思是,在X发生的条件下,Y的不确定性有
$$
H(Y|X)=\sum_{x \in X}\sum_{y \in Y}p(x, y)logp(y | x)
$$
将联合概率进行展开后发现:
$$
H(X, Y)=-\sum_{x \in X}p(x)logp(x)-\sum_{x \in X}\sum_{y \in Y}p(x, y)logp(y | x) = H(X)+H(Y|X)
$$</p>
<h2 id="xin-xi-zeng-yi"><a class="header-anchor no-hover-padding" href="#xin-xi-zeng-yi" aria-label="Anchor link for: xin-xi-zeng-yi"><span class="link-icon" aria-hidden="true"></span></a>
信息增益</h2>
<p>现在有属性a, 其可能有v个可能的取值,如果使用属性a来对样本D进行划分的话,易知会产生v个节点,那么所有属性为$a_v$的样本可记为$D^v$.,这时候再根据各个节点对应所占的比例$|D^v|/|D|$分配权重,就可以知道使用属性a对D进行划分的时候所获得的信息增益,也就是说使用整个样本的信息熵,减去通过属性a划分的信息熵之和就是信息增益.</p>
<p>现在假设样本D的信息熵为
$$
Ent(D)=-\sum_{k=1}^{|v|}p_klog_2p_k
$$
那么信息增益为:
$$
Gain(D,a)=Ent(D)-\sum_{v=1}^{V}\frac{|D^v|}{|D|}Ent(D^v)
$$</p>
<h2 id="ji-ni-bu-chun-du"><a class="header-anchor no-hover-padding" href="#ji-ni-bu-chun-du" aria-label="Anchor link for: ji-ni-bu-chun-du"><span class="link-icon" aria-hidden="true"></span></a>
基尼不纯度</h2>
<p>基尼不纯度是CART算法划分属性所使用的度量方法,其直观上的理解是从一个数据集D中任意抽取两个样本,其类别不一致的概率.其具体的公式如下:
$$
Gini(D)=\sum_{k=1}{|y|}\sum_{k^{'}\neq k}(p_kp_k')
$$</p>
<h1 id="jue-ce-shu-de-bu-tong-fen-lei-suan-fa"><a class="header-anchor no-hover-padding" href="#jue-ce-shu-de-bu-tong-fen-lei-suan-fa" aria-label="Anchor link for: jue-ce-shu-de-bu-tong-fen-lei-suan-fa"><span class="link-icon" aria-hidden="true"></span></a>
决策树的不同分类算法</h1>
<h2 id="id3suan-fa"><a class="header-anchor no-hover-padding" href="#id3suan-fa" aria-label="Anchor link for: id3suan-fa"><span class="link-icon" aria-hidden="true"></span></a>
ID3算法</h2>
<p>流程具体如下:</p>
<ol>
<li>首先考虑样本中只有一个类或者没有属性的情况</li>
<li>计算各个属性的信息增益后</li>
<li>选择信息增益最多的属性进行节点分类,建立各个节点分支</li>
<li>再依次的再各个节点中进行选择计算信息增益,返回步骤2重复迭代</li>
<li>到达指定的退出条件,没有特征或者信息增益较小
由于ID3 算法只有生成树的过程,没有剪枝等过程,所以可能过拟合.</li>
</ol>
<h2 id="c4-5"><a class="header-anchor no-hover-padding" href="#c4-5" aria-label="Anchor link for: c4-5"><span class="link-icon" aria-hidden="true"></span></a>
C4.5</h2>
<p>首先,信息增益比的定义是信息增益G(D,a)与训练数据集熵H(D)的比
$$
g_R(D,a)=\frac{g(D,a)}{H(D)}
$$</p>
<p>该C4.5算法则是针对于ID3算法的改进,在生成树的过程中使用了信息增益比来选择,而不是单纯的使用信息增益
算法过程如下:
假设 数据集D 特征集A 阀值ε</p>
<ol>
<li>如果数据中均为同一个类,则返回,算法结束</li>
<li>如果 $A=\varnothing$, 则返回一个单节点的树,并选择实例数最多的类,为该节点的类别,算法结束</li>
<li>选择其中信息增益比最大的节点</li>
<li>再依次选择各个节点,计算当前节点的内的信息增益比,进行迭代</li>
<li>最终达到指定的退出条件,即信息增益比过低,或者没有更多的特征时退出算法</li>
</ol>
<p>上面的构建的节点树都是分类树,只不过节点划分的方式不同.那么什么是回归树呢?</p>
<h1 id="hui-gui-shu-yuan-li"><a class="header-anchor no-hover-padding" href="#hui-gui-shu-yuan-li" aria-label="Anchor link for: hui-gui-shu-yuan-li"><span class="link-icon" aria-hidden="true"></span></a>
回归树原理</h1>
<p>回归树对于样本的划分,通过遍历所有输入变量，找到最优的切分变量j和最优的切分点s，即选择第j个特征$x^j$和它的取值s将输入空间划分为两部分，然后重复这个操作,对于连续性的样本值非常有效.
具体算法如下</p>
<ol>
<li>选择最优的切分变量j和最优的切分点s，求解
$$
min_{j,s}[min_{c_{1}}\sum_{x_{i}\in R_{1}(j,s)}(y_{i}-c_{1})^2+min_{c_{2}}\sum_{x_{i}\in R_{2}(j,s)}(y_{i}-c_{2})^2]
$$</li>
<li>遍历所有特征，对固定的特征扫描所有取值，找到使上式达到最小值的对(j,s).</li>
<li>用选定的对 (j,s)划分区域，并确定该区域的预测值；</li>
<li>继续对两个字区域调用上述步骤，直至满足停止条件；</li>
</ol>
<h2 id="cartfen-lei-shu"><a class="header-anchor no-hover-padding" href="#cartfen-lei-shu" aria-label="Anchor link for: cartfen-lei-shu"><span class="link-icon" aria-hidden="true"></span></a>
CART分类树</h2>
<p>CART分类树的全称是分类与回归树,主要的原理思想是将内部的节点特征取值为"是"或"否"两个值,左分支为是,右分支为否,这样整个决策树就可以在整个样本空间中求取对应的条件概率分布.
算法由特征选择和生成树以及前面两种算法所没有的剪枝构成,算法主要包括两个部分:树的生成与剪枝</p>
<h3 id="cartde-sheng-cheng"><a class="header-anchor no-hover-padding" href="#cartde-sheng-cheng" aria-label="Anchor link for: cartde-sheng-cheng"><span class="link-icon" aria-hidden="true"></span></a>
CART的生成</h3>
<p>从根节点开始，对节点计算现有特征的基尼指数，对每一个特征，例如AA，再对其每个可能的取值如aa,根据样本点对A=aA=a的结果的”是“与”否“划分为两个部分，利用
$$
Gini(D,A=a)=\frac{|D_{1}|}{|D|}Gini(D_{1})+\frac{|D_{2}|}{|D|}Gini(D_{2})
$$
进行计算；在所有可能的特征AA以及该特征所有的可能取值a中，选择基尼指数最小的特征及其对应的取值作为最优特征和最优切分点。然后根据最优特征和最优切分点，将本节点的数据集二分，生成两个子节点
对两个字节点递归地调用上述步骤，直至节点中的样本个数小于阈值，或者样本集的基尼指数小于阈值，或者没有更多特征后停止；</p>
<h3 id="cartde-jian-zhi"><a class="header-anchor no-hover-padding" href="#cartde-jian-zhi" aria-label="Anchor link for: cartde-jian-zhi"><span class="link-icon" aria-hidden="true"></span></a>
CART的剪枝</h3>
<p>剪枝就是对生成的树进行裁剪简化的过程,其一般是通过极小化决策树整体的损失函数或代价函数来实现.
CART的剪枝是通过两个步骤:</p>
<ol>
<li>从树的底部不断地剪枝直到根节点,形成对应的子树序列</li>
<li>通过交叉验证法,对子树的序列进行测试,并从中选取最优的子树</li>
</ol>
<h1 id="jue-ce-shu-fang-zhi-guo-ni-he-shou-duan"><a class="header-anchor no-hover-padding" href="#jue-ce-shu-fang-zhi-guo-ni-he-shou-duan" aria-label="Anchor link for: jue-ce-shu-fang-zhi-guo-ni-he-shou-duan"><span class="link-icon" aria-hidden="true"></span></a>
决策树防止过拟合手段</h1>
<p>决策树过拟合主要有两个手段,分别为early stopping与剪枝.</p>
<ol>
<li>earlystopping:限制选取的分类节点的总数,树的深度,节点中的实例数,阈值等</li>
<li>剪枝,即当前节点的划分无法带来决策树泛化性能的提升,增删除对应的节点</li>
</ol>
<h1 id="mo-xing-ping-gu"><a class="header-anchor no-hover-padding" href="#mo-xing-ping-gu" aria-label="Anchor link for: mo-xing-ping-gu"><span class="link-icon" aria-hidden="true"></span></a>
模型评估</h1>
<p>可以使用之前梳理的AUC ROC 交叉验证 随机抽样等方法,这里就不再赘述了.</p>
<h1 id="pythonke-shi-hua-jue-ce-shu-yu-dui-ying-de-han-shu-shi-xian"><a class="header-anchor no-hover-padding" href="#pythonke-shi-hua-jue-ce-shu-yu-dui-ying-de-han-shu-shi-xian" aria-label="Anchor link for: pythonke-shi-hua-jue-ce-shu-yu-dui-ying-de-han-shu-shi-xian"><span class="link-icon" aria-hidden="true"></span></a>
python可视化决策树与对应的函数实现</h1>
<pre class="z-code"><code><span class="z-text z-plain">import pydotplus
</span><span class="z-text z-plain">from sklearn.datasets import load_iris
</span><span class="z-text z-plain">from sklearn import tree
</span><span class="z-text z-plain">import collections
</span><span class="z-text z-plain"># Data Collection
</span><span class="z-text z-plain">X = [ [180, 15,0],     
</span><span class="z-text z-plain">      [177, 42,0],
</span><span class="z-text z-plain">      [136, 35,1],
</span><span class="z-text z-plain">      [174, 65,0],
</span><span class="z-text z-plain">      [141, 28,1]]
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">Y = [&#39;man&#39;, &#39;woman&#39;, &#39;woman&#39;, &#39;man&#39;, &#39;woman&#39;]    
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">data_feature_names = [ &#39;height&#39;, &#39;hair length&#39;, &#39;voice pitch&#39; ]
</span><span class="z-text z-plain"># Training
</span><span class="z-text z-plain">clf = tree.DecisionTreeClassifier()
</span><span class="z-text z-plain">clf = clf.fit(X,Y)
</span><span class="z-text z-plain"># Visualize data
</span><span class="z-text z-plain">dot_data = tree.export_graphviz(clf,
</span><span class="z-text z-plain">                                feature_names=data_feature_names,
</span><span class="z-text z-plain">                                out_file=None,
</span><span class="z-text z-plain">                                filled=True,
</span><span class="z-text z-plain">                                rounded=True)
</span><span class="z-text z-plain">graph = pydotplus.graph_from_dot_data(dot_data)
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">colors = (&#39;turquoise&#39;, &#39;orange&#39;)
</span><span class="z-text z-plain">edges = collections.defaultdict(list)
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">for edge in graph.get_edge_list():
</span><span class="z-text z-plain">    edges[edge.get_source()].append(int(edge.get_destination()))
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">for edge in edges:
</span><span class="z-text z-plain">    edges[edge].sort()    
</span><span class="z-text z-plain">    for i in range(2):
</span><span class="z-text z-plain">        dest = graph.get_node(str(edges[edge][i]))[0]
</span><span class="z-text z-plain">        dest.set_fillcolor(colors[i])
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">graph.write_png(&#39;tree.png&#39;)
</span></code></pre>
<p>主要的函数为</p>
<h1 id="can-kao"><a class="header-anchor no-hover-padding" href="#can-kao" aria-label="Anchor link for: can-kao"><span class="link-icon" aria-hidden="true"></span></a>
参考</h1>
<p><a href="https://blog.littleji.com/blog/20181225mlreview3/None">统计自然语言处理-宗成庆</a>
<a href="https://blog.littleji.com/blog/20181225mlreview3/None">机器学习-周志华</a>
<a href="https://blog.littleji.com/blog/20181225mlreview3/None">统计学习方法-李航</a>
<a href="https://blog.csdn.net/weixin_36586536/article/details/80468426">决策树(分类树、回归树</a>
<a href="https://pythonprogramminglanguage.com/decision-tree-visual-example/">Decision tree visual example</a></p>

        </section>

        
                
                
                    
                        
                        
                        
                    
                    
                        
                        
                        
                    
                
                
            <nav class="full-width article-navigation">
                <div><a href="https://blog.littleji.com/blog/20190219handovermemolist/" aria-label="Next" aria-describedby="left_title"><span class="arrow">←</span>&nbsp;Next</a>
                <p aria-hidden="true" id="left_title">软件项目交接清单(Software project handover checklist)</p></div>
                <div><a href="https://blog.littleji.com/blog/20181222mlreview2/" aria-label="Prev" aria-describedby="right_title">Prev&nbsp;<span class="arrow">→</span></a>
                <p aria-hidden="true" id="right_title">ML梳理之线性回归(LogisticRegression)</p></div>
            </nav>
        
        

        
            
            
            

            
        
            
            
            

            
        
            
            
            

            
        
            
            
            

            
        
        

    </article>
</main>

    <div id="button-container">
        
        
            <div id="toc-floating-container">
                <input type="checkbox" id="toc-toggle" class="toggle"/>
                <label for="toc-toggle" class="overlay"></label>
                <label for="toc-toggle" id="toc-button" class="button" title="Toggle Table of Contents">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 -960 960 960"><path d="M414.82-193.094q-18.044 0-30.497-12.32-12.453-12.319-12.453-30.036t12.453-30.086q12.453-12.37 30.497-12.37h392.767q17.237 0 29.927 12.487 12.69 12.486 12.69 30.203 0 17.716-12.69 29.919t-29.927 12.203H414.82Zm0-244.833q-18.044 0-30.497-12.487Q371.87-462.9 371.87-480.45t12.453-29.92q12.453-12.369 30.497-12.369h392.767q17.237 0 29.927 12.511 12.69 12.512 12.69 29.845 0 17.716-12.69 30.086-12.69 12.37-29.927 12.37H414.82Zm0-245.167q-18.044 0-30.497-12.32t-12.453-30.037q0-17.716 12.453-30.086 12.453-12.369 30.497-12.369h392.767q17.237 0 29.927 12.486 12.69 12.487 12.69 30.203 0 17.717-12.69 29.92-12.69 12.203-29.927 12.203H414.82ZM189.379-156.681q-32.652 0-55.878-22.829t-23.226-55.731q0-32.549 23.15-55.647 23.151-23.097 55.95-23.097 32.799 0 55.313 23.484 22.515 23.484 22.515 56.246 0 32.212-22.861 54.893-22.861 22.681-54.963 22.681Zm0-245.167q-32.652 0-55.878-23.134-23.226-23.135-23.226-55.623 0-32.487 23.467-55.517t56.12-23.03q32.102 0 54.721 23.288 22.62 23.288 22.62 55.775 0 32.488-22.861 55.364-22.861 22.877-54.963 22.877Zm-.82-244.833q-32.224 0-55.254-23.288-23.03-23.289-23.03-55.623 0-32.333 23.271-55.364 23.272-23.03 55.495-23.03 32.224 0 55.193 23.288 22.969 23.289 22.969 55.622 0 32.334-23.21 55.364-23.21 23.031-55.434 23.031Z"/></svg>
                </label>
                <div class="toc-content">
                    

<div class="toc-container">
    

    <ul>
        
            
            
                <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#xin-xi-lun-ji-chu">信息论基础</a>
                    
                        <ul>
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#shang">熵</a>
                                        
                                    </li>
                                
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#lian-he-shang">联合熵</a>
                                        
                                    </li>
                                
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#tiao-jian-shang">条件熵</a>
                                        
                                    </li>
                                
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#xin-xi-zeng-yi">信息增益</a>
                                        
                                    </li>
                                
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#ji-ni-bu-chun-du">基尼不纯度</a>
                                        
                                    </li>
                                
                            
                        </ul>
                    
                </li>
            
        
            
            
                <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#jue-ce-shu-de-bu-tong-fen-lei-suan-fa">决策树的不同分类算法</a>
                    
                        <ul>
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#id3suan-fa">ID3算法</a>
                                        
                                    </li>
                                
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#c4-5">C4.5</a>
                                        
                                    </li>
                                
                            
                        </ul>
                    
                </li>
            
        
            
            
                <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#hui-gui-shu-yuan-li">回归树原理</a>
                    
                        <ul>
                            
                                
                                    <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#cartfen-lei-shu">CART分类树</a>
                                        
                                            <ul>
                                                
                                                    
                                                        <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#cartde-sheng-cheng">CART的生成</a>
                                                            
                                                        </li>
                                                    
                                                
                                                    
                                                        <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#cartde-jian-zhi">CART的剪枝</a>
                                                            
                                                        </li>
                                                    
                                                
                                            </ul>
                                        
                                    </li>
                                
                            
                        </ul>
                    
                </li>
            
        
            
            
                <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#jue-ce-shu-fang-zhi-guo-ni-he-shou-duan">决策树防止过拟合手段</a>
                    
                </li>
            
        
            
            
                <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#mo-xing-ping-gu">模型评估</a>
                    
                </li>
            
        
            
            
                <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#pythonke-shi-hua-jue-ce-shu-yu-dui-ying-de-han-shu-shi-xian">python可视化决策树与对应的函数实现</a>
                    
                </li>
            
        
            
            
                <li><a href="https://blog.littleji.com/blog/20181225mlreview3/#can-kao">参考</a>
                    
                </li>
            
        
    </ul>
</div>


                </div>
            </div>
        

        
        

        
        <a href="#" id="top-button" class="no-hover-padding" title="Go to the top of the page">
            <svg viewBox="0 0 20 20" fill="currentColor"><path d="M3.293 9.707a1 1 0 010-1.414l6-6a1 1 0 011.414 0l6 6a1 1 0 01-1.414 1.414L11 5.414V17a1 1 0 11-2 0V5.414L4.707 9.707a1 1 0 01-1.414 0z"/></svg>
        </a>
    </div>


<script defer src="https://blog.littleji.com/js/mermaid.min.js"></script><span id="copy-success" class="hidden">
        Copied!
    </span>
    <span id="copy-init" class="hidden">
        Copy code to clipboard
    </span>
    <script defer src="https://blog.littleji.com/js/copyCodeToClipboard.min.js"></script>
    </div>
    <footer>
    <section>
        <nav class="socials nav-navs"><ul>
                        
                            <li>
                                <a class="nav-links no-hover-padding social" rel=" me"  href="https://github.com/littleji/">
                                    <img loading="lazy" alt="github" title="github" src="https://blog.littleji.com/social_icons/github.svg">
                                </a>
                            </li>
                        
                    
                </ul>
            
        </nav>

        
        <nav class="nav-navs">
                <small>
                    <ul>
                        
                        <li><a class="nav-links no-hover-padding" href="https:&#x2F;&#x2F;blog.littleji.com&#x2F;pages&#x2F;about&#x2F;">
                                about
                            </a>
                        </li>
                    
                        <li><a class="nav-links no-hover-padding" href="https:&#x2F;&#x2F;blog.littleji.com&#x2F;privacy&#x2F;">
                                privacy
                            </a>
                        </li>
                    
                        <li><a class="nav-links no-hover-padding" href="https:&#x2F;&#x2F;blog.littleji.com&#x2F;sitemap.xml">
                                sitemap
                            </a>
                        </li>
                    
                    </ul>
                </small>
        
        </nav>

        <div class="credits">
            <small>
                

                
                Powered by
                <a rel=""  href="https://www.getzola.org">Zola</a>
                &amp;
                <a rel=""  href="https://github.com/welpo/tabi">tabi</a>

                </small>
        </div>
    </section>

    <div id="searchModal" class="search-modal js" role="dialog" aria-labelledby="modalTitle">
    <h1 id="modalTitle" class="visually-hidden">Search</h1>
    <div id="modal-content">
        <div id="searchBar">
            <div class="search-icon" aria-hidden="true">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 -960 960 960">
                    <path d="M784-120 532-372q-30 24-69 38t-83 14q-109 0-184.5-75.5T120-580q0-109 75.5-184.5T380-840q109 0 184.5 75.5T640-580q0 44-14 83t-38 69l252 252-56 56ZM380-400q75 0 127.5-52.5T560-580q0-75-52.5-127.5T380-760q-75 0-127.5 52.5T200-580q0 75 52.5 127.5T380-400Z"/>
                </svg>
            </div>
            <input id="searchInput" role="combobox" autocomplete="off" spellcheck="false" aria-expanded="false" aria-controls="results-container" placeholder="Search…"/>
            <div id="clear-search" class="close-icon interactive-icon" tabindex="0" role="button" title="Clear search">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 -960 960 960">
                <path d="m256-200-56-56 224-224-224-224 56-56 224 224 224-224 56 56-224 224 224 224-56 56-224-224-224 224Z"/>
                </svg>
            </div>
        </div>
        <div id="results-container">
            <div id="results-info"><span id="zero_results"> No results</span>
                <span id="one_results"> 1 result</span>
                <span id="many_results"> $NUMBER results</span><span id="two_results"> $NUMBER results</span>
                <span id="few_results"> $NUMBER results</span>
            </div>
            <div id="results" role="listbox"></div>
        </div>
    </div>
</div>
</footer>

</body>

</html>
